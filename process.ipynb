{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import re\n",
    "import json\n",
    "source_dir = \"C:\\\\projects\\\\local\\\\video_analysis\"\n",
    "video_dir = 'video'\n",
    "audio_dir = 'audio'\n",
    "text_dir = 'text-faster'\n",
    "date_dir = 'date'\n",
    "ffmpeg_path = os.environ['LOCALAPPDATA'] + \"\\\\Microsoft\\\\WinGet\\\\Packages\\\\Gyan.FFmpeg_Microsoft.Winget.Source_8wekyb3d8bbwe\\\\ffmpeg-6.0-full_build\\\\bin\\\\ffmpeg.exe\"\n",
    "import whisper\n",
    "from faster_whisper import WhisperModel\n",
    "import torch\n",
    "os.environ[\"OPENAI_API_TYPE\"]=\"azure\"\n",
    "os.environ[\"OPENAI_API_VERSION\"]=\"2023-05-15\"\n",
    "whisper_model_name = None #'medium.en'\n",
    "faster_whisper_model_name = 'large-v2'\n",
    "whisper_device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "if whisper_model_name is None:\n",
    "    print('Using faster-whisper model {} on device {}'.format(faster_whisper_model_name, whisper_device))\n",
    "else:\n",
    "    print('Using whisper model {} on device {}'.format(whisper_model_name, whisper_device))\n",
    "\n",
    "# get settings from files\n",
    "with open(os.path.join(source_dir, \"openai-base.txt\"), \"r\") as f:\n",
    "    os.environ[\"OPENAI_API_BASE\"] = f.read()\n",
    "with open(os.path.join(source_dir, \"openai-key.txt\"), \"r\") as f:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = f.read()\n",
    "\n",
    "from langchain.llms import AzureOpenAI\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.prompts.chat import PromptTemplate, ChatPromptTemplate\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.chains import (\n",
    "    StuffDocumentsChain,\n",
    "    LLMChain,\n",
    "    ReduceDocumentsChain,\n",
    "    MapReduceDocumentsChain,\n",
    "    AnalyzeDocumentChain,\n",
    ")\n",
    "chat_model = AzureChatOpenAI(\n",
    "    deployment_name=\"gpt-35-turbo-16k\",\n",
    "    temperature=0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all mp3 files in source_dir (and subdirectories) that do not yet have a mp3 file and convert them with ffmpeg\n",
    "def move_by_extension(src, target, extension, newEx):\n",
    "    print('moving {} from {} to {}'.format(extension, os.path.join(source_dir, src), os.path.join(source_dir, target)))\n",
    "    start = os.path.join(source_dir, src)\n",
    "    for root, dirs, files in os.walk(start):\n",
    "        relpath = os.path.relpath(root, start)\n",
    "        for file in files:\n",
    "            if file.endswith(extension):\n",
    "                f = os.path.join(source_dir, src, relpath, file)\n",
    "                t = os.path.join(source_dir, target, relpath, file[:-len(extension)] + newEx)\n",
    "                os.makedirs(os.path.dirname(t), exist_ok=True)\n",
    "                os.rename(f, t)\n",
    "                # print('moving {} to {}'.format(f, t))\n",
    "                # return\n",
    "# use this to reorg from old structure to new structure\n",
    "# move_by_extension(video_dir, audio_dir, '.mp3', '.mp3')\n",
    "# move_by_extension(video_dir, text_dir, '.txt', '.txt')\n",
    "# move_by_extension(video_dir, date_dir, '.date', '.txt')\n",
    "# move_by_extension(video_dir, 'ext-folder', '.ext', '.txt')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all mp4 files in source_dir (and subdirectories) that do not yet have a mp3 file and convert them with ffmpeg\n",
    "def process_files():\n",
    "    start = os.path.join(source_dir, video_dir)\n",
    "    for root, dirs, files in os.walk(start):\n",
    "        relpath = os.path.relpath(root, start)\n",
    "        for file in files:\n",
    "            if file.endswith(\".mp4\"):\n",
    "                mp4_file = os.path.join(source_dir, video_dir, relpath, file)\n",
    "                mp3_file = os.path.join(source_dir, audio_dir, relpath, file[:-4] + '.mp3')\n",
    "                if not os.path.isfile(mp3_file):\n",
    "                    print('want to create {} from {}'.format(mp3_file, mp4_file))\n",
    "                    return\n",
    "                    cmd = [ffmpeg_path, '-i', mp4_file, '-vn', '-ar', '44100', '-ac', '2', '-ab', '192k', '-f', 'mp3', mp3_file]\n",
    "                    print(cmd)\n",
    "                    proc = subprocess.Popen(cmd)\n",
    "                    result = proc.wait()\n",
    "                    print(\"{} - processed from {}\".format(result, mp4_file))\n",
    "process_files()\n",
    "print('generated MP3s for all MP4s in ' + source_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all mp3 files in source_dir (and subdirectories) that do not yet have a txt file and convert them with whisper\n",
    "def process_files():\n",
    "    model = None\n",
    "    start = os.path.join(source_dir, audio_dir)\n",
    "    for root, dirs, files in os.walk(start):\n",
    "        relpath = os.path.relpath(root, start)\n",
    "        for file in files:\n",
    "            if file.endswith(\".mp3\"):\n",
    "                mp3_file = os.path.join(source_dir, audio_dir, relpath, file)\n",
    "                txt_file = os.path.join(source_dir, text_dir, relpath, file[:-4] + '.txt')\n",
    "                json_file = os.path.join(source_dir, text_dir, relpath, file[:-4] + '.json')\n",
    "                if not os.path.isfile(txt_file) or not(os.path.isfile(json_file)):\n",
    "                    print('using {} to make {} and {}'.format(mp3_file, txt_file, json_file))\n",
    "                    if model is None:\n",
    "                        if whisper_model_name is None:\n",
    "                            print('loading {} faster-whisper model on device {}...'.format(faster_whisper_model_name, whisper_device.type))\n",
    "                            model = WhisperModel(faster_whisper_model_name, device=whisper_device.type, compute_type=\"float16\")\n",
    "                            print('loaded faster-whisper model - processing file')\n",
    "                        else:\n",
    "                            print('loading {} whisper model on device {}...'.format(whisper_model_name, whisper_device))\n",
    "                            model = whisper.load_model(whisper_model_name, device=whisper_device)\n",
    "                            print('loaded whisper model - processing file')\n",
    "\n",
    "                    segments = None\n",
    "                    if whisper_model_name is None:\n",
    "                        segments, info = model.transcribe(mp3_file, beam_size=5)\n",
    "                        # force evaluation now\n",
    "                        segments = list(segments)\n",
    "                    else:\n",
    "                        result = model.transcribe(mp3_file)\n",
    "                        segments = result['segments']\n",
    "\n",
    "                        # result has the following structure:\n",
    "                        #  text: string\n",
    "                        #  language: string\n",
    "                        #  segments: array of\n",
    "                        #    id: number\n",
    "                        #    seek: number\n",
    "                        #    start: number\n",
    "                        #    end: number\n",
    "                        #    text: string\n",
    "                        #    tokens: number[]\n",
    "                        #    temperature: number\n",
    "                        #    avg_logprob: number\n",
    "                        #    compression_ratio: number\n",
    "                        #    no_speech_prob: number\n",
    "\n",
    "                    # if we used text, we'll get one giant line.  Instead, we'll use segments\n",
    "                    print('got {} segments from {}'.format(len(segments), mp3_file))\n",
    "                    os.makedirs(os.path.dirname(txt_file), exist_ok=True)\n",
    "                    with open(txt_file, 'w', encoding='utf-8') as f:\n",
    "                        for segment in segments:\n",
    "                            if whisper_model_name is None:\n",
    "                                f.write(segment.text.strip() + '\\n')\n",
    "                            else:\n",
    "                                f.write(segment['text'].strip() + '\\n')\n",
    "                    tojson = segments\n",
    "                    if whisper_model_name is None:\n",
    "                        # convert list of tuples to list of dicts\n",
    "                        tojson = []\n",
    "                        for segment in segments:\n",
    "                            # completely guessed by CoPilot - I just had to change it from a [0]/etc. to .id/etc.\n",
    "                            tojson.append({\n",
    "                                'id': segment.id,\n",
    "                                'seek': segment.seek,\n",
    "                                'start': segment.start,\n",
    "                                'end': segment.end,\n",
    "                                'text': segment.text,\n",
    "                                'tokens': segment.tokens,\n",
    "                                'temperature': segment.temperature,\n",
    "                                'avg_logprob': segment.avg_logprob,\n",
    "                                'compression_ratio': segment.compression_ratio,\n",
    "                                'no_speech_prob': segment.no_speech_prob,\n",
    "                            })\n",
    "\n",
    "                    with open(json_file, 'w', encoding='utf-8') as f:\n",
    "                        f.write(json.dumps(tojson))\n",
    "                    print('wrote to {} and {}'.format(txt_file, json_file))\n",
    "process_files()\n",
    "print('generated TXTs for all MP3s in ' + source_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are a helpful assistant that identifies the date a file was created based on information in the filename.\n",
    "    All dates are between 2019 and 2030, and any dates in the filename are written with the month before the date (ie. american style).\n",
    "    The resulting date should be formatted as YYYY-mm-dd - ie. 2021-02-15.\n",
    "    Your response should _only_ contain the date, and nothing else.\n",
    "    \"\"\"),\n",
    "    (\"human\", \"{text}\"),\n",
    "])\n",
    "chain = chat_prompt | chat_model\n",
    "\n",
    "# find all txt files in source_dir (and subdirectories) that do not yet have a date file and ask the LLM to guess the date\n",
    "def process_files():\n",
    "    start = os.path.join(source_dir, text_dir)\n",
    "    for root, dirs, files in os.walk(start):\n",
    "        relpath = os.path.relpath(root, start)\n",
    "        for file in files:\n",
    "            if file.endswith(\".txt\"):\n",
    "                txt_file = os.path.join(source_dir, text_dir, relpath, file)\n",
    "                date_file = os.path.join(source_dir, date_dir, relpath, file[:-4] + '.txt')\n",
    "                if not os.path.isfile(date_file):\n",
    "                    print('getting date for {} to {}'.format(txt_file, date_file))\n",
    "                    result = chain.invoke({ \"text\": txt_file})\n",
    "                    date = result.content\n",
    "                    # use a regular expression to make sure date looks like YYYY-mm-dd\n",
    "                    if not re.match(r'^\\d{4}-\\d{2}-\\d{2}$', date):\n",
    "                        print('invalid date: {} generated for {}'.format(date, txt_file))\n",
    "                        continue\n",
    "                    os.makedirs(os.path.dirname(date_file), exist_ok=True)\n",
    "                    with open(date_file, 'w') as f:\n",
    "                        f.write(date)\n",
    "process_files()\n",
    "print('generated DATEs for all TXTs in ' + source_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ok, now for the real work.\n",
    "#  1. given a question and answer-extension, find all files with a txt+date file, but no answer-extension file\n",
    "#  2. ask the LLM to answer the question based on the file\n",
    "#  3. write the answer to the answer-extension file\n",
    "\n",
    "with open(os.path.join(source_dir, \"question.input\"), \"r\") as f:\n",
    "    question = f.read().strip()\n",
    "with open(os.path.join(source_dir, \"answer-dir.input\"), \"r\") as f:\n",
    "    answer_dir = f.read().strip()\n",
    "\n",
    "# # heavily based on https://github.com/langchain-ai/langchain/blob/master/libs/langchain/langchain/chains/combine_documents/map_reduce.py\n",
    "# document_prompt = PromptTemplate(\n",
    "#     input_variables=[\"page_content\"],\n",
    "#     template=\"{page_content}\"\n",
    "# )\n",
    "# document_variable_name = \"context\"\n",
    "# # The prompt here should take as an input variable the\n",
    "# # `document_variable_name`\n",
    "# prompt = PromptTemplate.from_template(\n",
    "#     \"\"\"You are a helpful assistant that summarizes existing content with the goal of answering these questions:\n",
    "#     {}\n",
    "#     If the content supplied isn't relevant to the question, you will say so.\n",
    "#     \"\"\".format(question) + \"Summarize this content: {context}\"\n",
    "# )\n",
    "# llm_chain = LLMChain(llm=chat_model, prompt=prompt)\n",
    "# # chat_chain = chat_prompt | chat_model\n",
    "# # chat_chain = ChatChain()\n",
    "# # We now define how to combine these summaries\n",
    "# reduce_prompt = PromptTemplate.from_template(\n",
    "#     \"Combine these summaries: {context}\"\n",
    "# )\n",
    "# reduce_llm_chain = LLMChain(llm=chat_model, prompt=reduce_prompt)\n",
    "# combine_documents_chain = StuffDocumentsChain(\n",
    "#     llm_chain=reduce_llm_chain,\n",
    "#     document_prompt=document_prompt,\n",
    "#     document_variable_name=document_variable_name\n",
    "# )\n",
    "# reduce_documents_chain = ReduceDocumentsChain(\n",
    "#     combine_documents_chain=combine_documents_chain,\n",
    "# )\n",
    "# chain = MapReduceDocumentsChain(\n",
    "#     llm_chain=llm_chain,\n",
    "#     reduce_documents_chain=reduce_documents_chain,\n",
    "# )\n",
    "\n",
    "# based on https://python.langchain.com/docs/use_cases/question_answering/analyze_document\n",
    "qa_chain = load_qa_chain(chat_model, chain_type=\"map_reduce\")\n",
    "qa_document_chain = AnalyzeDocumentChain(combine_docs_chain=qa_chain)\n",
    "\n",
    "# find all txt files in source_dir (and subdirectories) that have a text file and a date file, but no answer-dir file\n",
    "def process_files():\n",
    "    start = os.path.join(source_dir, text_dir)\n",
    "    for root, dirs, files in os.walk(start):\n",
    "        relpath = os.path.relpath(root, start)\n",
    "        for file in files:\n",
    "            if file.endswith(\".txt\"):\n",
    "                text_file = os.path.join(source_dir, text_dir, relpath, file)\n",
    "                date_file = os.path.join(source_dir, date_dir, relpath, file)\n",
    "                answer_file = os.path.join(source_dir, answer_dir, relpath, file)\n",
    "                if os.path.isfile(text_file) and os.path.isfile(date_file) and not os.path.isfile(answer_file):\n",
    "                    with open(text_file, \"r\", encoding='utf-8') as f:\n",
    "                        content = f.read().strip()\n",
    "                    with open(date_file, \"r\") as f:\n",
    "                        date = f.read().strip()\n",
    "                    print('getting answer for {}: {}'.format(date, text_file))\n",
    "                    answer = qa_document_chain.run(input_document=content, question=question)\n",
    "                    # result = chain.invoke({ \"input_documents\": [Document(page_content=content)] })\n",
    "                    # answer = result['output_text']\n",
    "                    print('writing answer to {}'.format(answer_file))\n",
    "                    os.makedirs(os.path.dirname(answer_file), exist_ok=True)\n",
    "                    with open(answer_file, 'w', encoding='utf-8') as f:\n",
    "                        f.write(answer)\n",
    "process_files()\n",
    "print('generated {} for all TXTs in {}'.format(answer_dir, os.path.join(source_dir, text_dir)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now find and summarize the results\n",
    "with open(os.path.join(source_dir, \"answer-dir.input\"), \"r\") as f:\n",
    "    answer_dir = f.read().strip()\n",
    "\n",
    "results = []\n",
    "\n",
    "# find all txt files in source_dir (and subdirectories) that have an answer and a date file\n",
    "def process_files():\n",
    "    start = os.path.join(source_dir, answer_dir)\n",
    "    for root, dirs, files in os.walk(start):\n",
    "        relpath = os.path.relpath(root, start)\n",
    "        for file in files:\n",
    "            if file.endswith(\".txt\"):\n",
    "                if file == 'summary.txt' and relpath == '':\n",
    "                    continue\n",
    "                answer_file = os.path.join(source_dir, answer_dir, relpath, file)\n",
    "                date_file = os.path.join(source_dir, date_dir, relpath, file)\n",
    "                text_file = os.path.join(source_dir, text_dir, relpath, file)\n",
    "                if os.path.isfile(date_file) and os.path.isfile(answer_file):\n",
    "                    with open(date_file, \"r\") as f:\n",
    "                        date = f.read().strip()\n",
    "                    with open(answer_file, \"r\", encoding='utf-8') as f:\n",
    "                        answer = f.read().strip()\n",
    "                    results.append(('{} - {}'.format(date, os.path.join(relpath, file)), answer))\n",
    "process_files()\n",
    "\n",
    "# sort results by date and output\n",
    "results.sort(key=lambda x: x[0])\n",
    "outfile = os.path.join(source_dir, answer_dir, 'summary.txt')\n",
    "with open(outfile, 'w') as f:\n",
    "    for result in results:\n",
    "        f.write('{}\\n{}\\n\\n'.format(result[0], result[1]))\n",
    "print('wrote {} results to {}'.format(len(results), outfile))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
