{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import re\n",
    "source_dir = \"C:\\\\projects\\\\local\\\\video_analysis\"\n",
    "ffmpeg_path = os.environ['LOCALAPPDATA'] + \"\\\\Microsoft\\\\WinGet\\\\Packages\\\\Gyan.FFmpeg_Microsoft.Winget.Source_8wekyb3d8bbwe\\\\ffmpeg-6.0-full_build\\\\bin\\\\ffmpeg.exe\"\n",
    "import whisper\n",
    "os.environ[\"OPENAI_API_TYPE\"]=\"azure\"\n",
    "os.environ[\"OPENAI_API_VERSION\"]=\"2023-05-15\"\n",
    "\n",
    "# get settings from files\n",
    "with open(source_dir + \"\\\\..\\\\openai-base.txt\", \"r\") as f:\n",
    "    os.environ[\"OPENAI_API_BASE\"] = f.read()\n",
    "with open(source_dir + \"\\\\..\\\\openai-key.txt\", \"r\") as f:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = f.read()\n",
    "\n",
    "from langchain.llms import AzureOpenAI\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "llm = AzureOpenAI(\n",
    "    deployment_name=\"gpt-35-turbo\"\n",
    ")\n",
    "chat_model = AzureChatOpenAI(\n",
    "    deployment_name=\"gpt-35-turbo\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all mp4 files in source_dir (and subdirectories) that do not yet have a mp3 file and convert them with ffmpeg\n",
    "def process_files():\n",
    "    for root, dirs, files in os.walk(source_dir):\n",
    "        for file in files:\n",
    "            if file.endswith(\".mp4\"):\n",
    "                mp4_file = os.path.join(root, file)\n",
    "                mp3_file = mp4_file[:-4] + '.mp3'\n",
    "                if not os.path.isfile(mp3_file):\n",
    "                    cmd = [ffmpeg_path, '-i', mp4_file, '-vn', '-ar', '44100', '-ac', '2', '-ab', '192k', '-f', 'mp3', mp3_file]\n",
    "                    print(cmd)\n",
    "                    proc = subprocess.Popen(cmd)\n",
    "                    result = proc.wait()\n",
    "                    print(\"{} - processed from {}\".format(result, mp4_file))\n",
    "process_files()\n",
    "print('generated MP3s for all MP4s in ' + source_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = whisper.load_model('medium.en', device='cuda')\n",
    "\n",
    "# find all mp3 files in source_dir (and subdirectories) that do not yet have a txt file and convert them with whisper\n",
    "def process_files():\n",
    "    for root, dirs, files in os.walk(source_dir):\n",
    "        for file in files:\n",
    "            if file.endswith(\".mp3\"):\n",
    "                mp3_file = os.path.join(root, file)\n",
    "                txt_file = mp3_file[:-4] + '.txt'\n",
    "                if not os.path.isfile(txt_file):\n",
    "                    print('processing {}'.format(mp3_file))\n",
    "                    result = model.transcribe(mp3_file)\n",
    "                    # result has the following structure:\n",
    "                    #  text: string\n",
    "                    #  language: string\n",
    "                    #  segments: array of\n",
    "                    #    id: number\n",
    "                    #    seek: number\n",
    "                    #    start: number\n",
    "                    #    end: number\n",
    "                    #    text: string\n",
    "                    #    tokens: number[]\n",
    "                    #    temperature: number\n",
    "                    #    avg_logprob: number\n",
    "                    #    compression_ratio: number\n",
    "                    #    no_speech_prob: number\n",
    "\n",
    "                    # if we used text, we'll get one giant line.  Instead, we'll use segments\n",
    "                    print('got {} segments from {}'.format(len(result['segments']), mp3_file))\n",
    "                    with open(txt_file, 'w') as f:\n",
    "                        for segment in result['segments']:\n",
    "                            f.write(segment['text'] + '\\n')\n",
    "                    print('wrote to {}'.format(txt_file))\n",
    "process_files()\n",
    "print('generated TXTs for all MP3s in ' + source_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are a helpful assistant that identifies the date a file was created based on information in the filename.\n",
    "    All dates are between 2019 and 2030, and any dates in the filename are written with the month before the date (ie. american style).\n",
    "    The resulting date should be formatted as YYYY-mm-dd - ie. 2021-02-15.\n",
    "    Your response should _only_ contain the date, and nothing else.\n",
    "    \"\"\"),\n",
    "    (\"human\", \"{text}\"),\n",
    "])\n",
    "chain = chat_prompt | chat_model\n",
    "\n",
    "# find all txt files in source_dir (and subdirectories) that do not yet have a date file and ask the LLM to guess the date\n",
    "def process_files():\n",
    "    for root, dirs, files in os.walk(source_dir):\n",
    "        for file in files:\n",
    "            if file.endswith(\".txt\"):\n",
    "                txt_file = os.path.join(root, file)\n",
    "                date_file = txt_file[:-4] + '.date'\n",
    "                if not os.path.isfile(date_file):\n",
    "                    print('getting date for {}'.format(txt_file))\n",
    "                    result = chain.invoke({ \"text\": txt_file})\n",
    "                    date = result.content\n",
    "                    # use a regular expression to make sure date looks like YYYY-mm-dd\n",
    "                    if not re.match(r'^\\d{4}-\\d{2}-\\d{2}$', date):\n",
    "                        print('invalid date: {} generated for {}'.format(date, txt_file))\n",
    "                        continue\n",
    "                    with open(date_file, 'w') as f:\n",
    "                        f.write(date)\n",
    "process_files()\n",
    "print('generated DATEs for all TXTs in ' + source_dir)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
